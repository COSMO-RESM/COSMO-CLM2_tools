#+TITLE: COSMO_CLM^2 tools
#+AUTHOR: Matthieu Leclair
#+EXPORT_FILE_NAME: README
#+STARTUP: overview

* Description
  This utility enables the automated creation and run of COSMO_CLM^2
  simulations. It is written in Python3, with some automatically
  generated bash scripts for interaction with scheduling systems, and
  with a view to be extensible to different machines (so far Piz Daint
  at CSCS and Mistral at DKRZ are supported).

  The utility provides essentially one command, =cc2_create_case=,
  which builds a case in a dedicated directory based on the user's
  input provided either through command line arguments or an xml setup
  file. During case creation, the following steps occur:
  - all necessary files (input data files, executables and potentially
    modified namelists) are transfered to the case directory or placed
    in a subdirectory according to namelists specifications when
    needed. Based on the user's specifications, either whole of the
    input data or only the part needed for the first chunk of the
    simulation (for long simulation needing restarts) is getting
    transferred.
  - bash job scripts are created for running, transferring input data
    and archiving output files.
  - case properties not stored in namelists (e.g. length of chunks,
    archiving options, run/transfer status etc) are written to a local
    xml configuration file (not ot be confused with the user's xml
    setup file)

  The first run job is then submitted and run, transfer and archive
  jobs are subsequently organized as represented on the following
  chart.

  #+CAPTION: Schematics of jobs organization
  #+NAME: fig:jobs_organization
  [[submit_sync.svg]]
  
* Install
  You can now install either for python 2 or 3 (python3 recommanded as
  python2 compatibility might not be ensured in the future) and
  without cloning and installing manually
  - Install COSMO_CLM2_tools
    #+BEGIN_SRC shell
      module load cray-python/3.6.5.1
      pip3 install --user git+https://github.com/COSMO-RESM/COSMO_CLM2_tools.git
    #+END_SRC
    use ~--upgrade~ for later updates
    #+BEGIN_SRC shell
      module load cray-python/3.6.5.1
      pip3 install --user --upgrade git+https://github.com/COSMO-RESM/COSMO_CLM2_tools.git
    #+END_SRC
  - Make sure =~/.local/bin= is in your path

* Usage
  In this section we explain in more details how to use the
  utility. As mentionned in the desciption section, it mostly provides
  the ~cc2_create_case~ command to the user. ~cc2_control_case~ is
  also provided but is mostly usefull for the utility itself. Note
  that ~cc2_compile_clm~ is also provided to flexibly compile the
  Commnity Land Model. It is independant from running a COSMO_CLM^2
  simulation and is decribed later.

** How to provide user's specifications
   The first thing to describe is how users specifications are
   provided to the ~cc2_create_case~ command. Almost all options can
   be passed either by command line arguments or read from an xml
   setup file. The later is given by the ~-s, --setup_file~ option.
   The overall idea is that the user can store the most "stable"
   options in the setup file and try other options by directly
   providing them to the command line. It's anyways up to the user to
   make use of this flexibility keeping in mind that *any option
   provided through the command line has precedence over its setup
   file counterpart*. As exemplified bellow, options are grouped under
   different nodes in the xml setup file:
   - the ~machine~ node containing only the machine name. This is
     subject to change and might eventually move to the ~main~ node
   - the ~main~ node contains machine-independent options
   - machine specific options are stored under the node named after
     the machine. Note that options common to several machines, like
     scheduler related options, are also stored there as the default
     value might vary from machine to machine.

   #+BEGIN_SRC xml
     <?xml version="1.0" encoding="utf-8"?>
     <setup>
       <machine></machine>
       <main>
         <name>COSMO_CLM2</name>
         <install_dir></install_dir>
         <archive_dir></archive_dir>
         <cosmo_only></cosmo_only>
         <start_date></start_date>
         <end_date></end_date>
         <run_length></run_length>
         <cos_in>./COSMO_input</cos_in>
         <cos_nml>./COSMO_nml</cos_nml>
         <cos_exe>./cosmo</cos_exe>
         <cesm_in>./CESM_input</cesm_in>
         <cesm_nml>./CESM_nml</cesm_nml>
         <cesm_exe>./cesm.exe</cesm_exe>
         <oas_in>./OASIS_input</oas_in>
         <oas_nml>./OASIS_nml</oas_nml>
         <ncosx type="int"></ncosx>
         <ncosy type="int"></ncosy>
         <ncosio type="int"></ncosio>
         <ncesm type="int"></ncesm>
         <gpu_mode type="py_eval">False</gpu_mode>
         <dummy_day type="py_eval">False</dummy_day>
         <transfer_all type="py_eval">False</transfer_all>
         <input_type>file</input_type>
       </main>
       <daint>
         <account></account>
         <partition></partition>
         <modules_opt>switch</modules_opt>
         <pgi_version></pgi_version>
         <shebang>#!/bin/bash</shebang>
         <run_time>24:00:00</run_time>
         <transfer_time>02:00:00</transfer_time>
         <archive_time>03:00:00</archive_time>
       </daint>
       <mistral>
         <account></account>
         <partition></partition>
         <run_time>10:00:00</run_time>
       </mistral>
     </setup>
   #+END_SRC

   The command line help ~cc2_create_case --help~ also displays
   options following a similar structure.

** User options
   Here we describe all options in details. An option ~--option_bla~
   in the command line has the node ~<option_bla>value</option_bla>~
   as counterpart in the xml setup file. In the later, in case the
   option value has to be interpreted as something else than a string,
   the type must be provided as an attribute to the option node (see
   example from the previous section). It can be either ~"py_eval"~
   for directly evaluating the string by python or any valid python
   type.

   For boolean options you will see "type: bool, using anything Python
   can parse as a boolean" in the command line help instead of an
   option that doesn't require an argument. So for instance you might
   have to specify ~--gpu_mode 1~ or ~--gpu_mode bla~ instead of the
   more usual ~--gpu_mode~ only. For the xml file, you can specify in
   both ways: either ~type="py_eval"~ as attribute and ~True~ or
   ~False~ for the value or ~type="bool"~ and anything Python can
   parse as a boolean for the value. This is due to the internals of
   the code and how defaults are implemented.

*** Basic options
    - =-s, --setup_file= path to the xml setup file. Beware that all
      relative paths provided in the setup file or directly to the
      command line are relative to where the ~cc2_create_case~ command
      gets executed.
    - =--machine= specify the machine name. It has to be given either by
      the command line or the in the setup file.
    - ~--name~ case name. The working directory will be named after
      the case name. It also affects CESM output file names.
    - ~--install_dir~ the case working directory gets created as
      ~INSTALL_DIR/CASE_NAME~

*** Case dates and restarts
    - ~--start_date~ simulation start date formatted as 'YYYY-MM-DD-HH'
    - ~--end_date~ simulation end date formatted as 'YYYY-MM-DD-HH'
    - ~--run_length~ set simulation length if end_date not specified
      or run length between restarts otherwise. It can be given in one
      of the following forms: 'N1yN2m', 'N1y', 'N2m' or 'N3d'. N1, N2
      and N4 are arbitrary integers (N2>12 possible) and 'y', 'm' and
      'd' stand respectively for years, months and days.

*** Case input : data, namelists and executables
    So far the following options have default values but these
    defaults might disappear in favor of an error thrown in case none
    of the setup file or the command line arguments contain it.
    - ~--cos_in~ COSMO input files directory (default: ./COSMO_input)
    - ~--cos_nml~ COSMO namelists directory (default: ./COSMO_nml)
    - ~--cos_exe~ path to COSMO executable (default: ./cosmo)
    - ~--cesm_in~ CESM input files directory (default: ./CESM_input)
    - ~--cesm_nml~ CESM namelists directory (default: ./CESM_nml)
    - ~--cesm_exe~ path to CESM executable (default: ./cesm.exe)
    - ~--oas_in~ OASIS input files directory (default: ./OASIS_input)
    - ~--oas_nml~ OASIS namelists directory (default:
      ./OASIS_nml). *WARNING*: it must contain a =namcouple_tmpl= file
      in which there has to be a =_runtime_= placeholder so that the
      tool can insert the right run time at each restart.

*** Domain decomposition and tasks organization
    - ~--ncosx~ number of COSMO subdomains along the 'x-axis' (type:
      int, default: from INPUT_ORG namelist)
    - ~--ncosy~ number of COSMO subdomains along the 'y-axis' (type:
      int, default: from INPUT_ORG namelist)
    - ~--ncosio~ number of COSMO tasks dedicated to i/o work, not
      tested (type: int, default: from INPUT_ORG namelist)
    - ~--ncesm~ number of CESM subdomains (type: int, default: from
      drv_in namelist)
    The user has to make sure that the total number of tasks ~ncosx *
    ncosy + ncosio + ncesm~ add up to a integer times the number of
    tasks per node on the machine. When COSMO is ran in gpu mode,
    ~ncesm~ is ignored and all available tasks are associated to CESM,
    i.e. ~n_nodes * (n_tasks_per_node - 1)~

*** Run options
    - ~--cosmo_only~ run only cosmo with the build-in soil model TERRA
      (type: bool, using anything Python can parse as a boolean,
      default: False). *Warning*: provide a COSMO executable compiled
      accordingly.
    - ~--start_mode~ specify the type of start requested (choices:
      'startup', 'continue', 'restart', default: 'startup').
      - 'startup' is for simulations with a classical initial state.
      - 'continue' is for continuing an existing simulation. Use in
        conjunction with the ~restart_date~, ~cos_rst~ and ~cesm_rst~
        options. *Warning*: the original and continued cases need to
        have the same name. Also do not modify the ~start_date~
        option, keep the original case start date and use the
        ~restart_date~ option for specifying when to continue.
      - 'restart' is for restarting from another case, *Warning*:
        doesn't work yet!
    - ~--restart_date~ restart/continue date formatted as
      YYYY-MM-DD-HH
    - ~--cos_rst~ path to the COSMO restart file. Compresed restart
      files with extension '.gz' or '.bz2' are accepted
    - ~--cesm_rst~ path to the directory containing CESM restart
      files. Archives, compresed or not, with extension '.tar',
      '.tgz', '.tar.gz', '.tbz' or '.tar.bz2' are accepted.
    - ~--gpu_mode~ run COSMO on gpu (type: bool, using anything Python
      can parse as a boolean, default: False). *Warning*: provide a
      COSMO executable compiled accordingly.
    - ~--dummy_day~ extend the last chunk by 1 day in order to get
      last COSMO output (type: bool, using anything Python can parse
      as a boolean, default: True). *Warning*: make sure the
      corresponding input file are available in the COSMO input
      directory.
    - ~--gen_oasis~ generate OASIS auxiliary files. The simulation
      will crash after generating these files. This is normal, just
      transfer the new files back where you need. This is a command
      line only option, cannot be set in the setup file.
    - ~--no_submit~ do not submit job after case install. This is
      useful for debug or check but also if one needs to modify the
      run, transfer or archive job scripts. The case can then be
      submitted by hand from the case directory. This is a command
      line only option, cannot be set in the setup file.
    
*** Transfer of input data during simulation
    - ~--transfer_all~ transfer all model input files at once before
      starting the simulation. If not, only transfer the data needed
      to run the first chunk (type: bool, using anything Python can
      parse as a boolean, default: True). This default value will most
      probably be switched to False in a close future.
    - ~--input_type~ either 'file' or 'symlink'. In the second case,
      only a link to the original input file is created in the working
      directory instead of an actual file. *Warning* the file system
      where the original input files are stored has to be accessible
      from the compute nodes. use in conjunction with
      ~--transfer_all=1~.

*** Archiving
    - ~--archive_dir~ directory where output and restart files are
      archived (default: None). If not provided either to the command
      line or by the setup file, no archiving is performed.
    - ~--archive_rm~ remove original output files from the case
      directory when archiving (type: bool, using anything Python can
      parse as a boolean, default: False). Note that this option has
      no effect on the archiving of restart files who are needed by
      the potential next run by definition
    - ~--archive_cmpression~ specify which compression algorithm is
      used before transferring the archive (available choices: 'none',
      'gzip' and 'bzip2', default: 'none'). For heavy output
      simulations, you might be better off compressing the archived
      output data yourself.
    - ~--archive_cesm~ archive or not the CESM output (type: bool,
      using anything Python can parse as a boolean, default:
      True). The idea is that a CESM output stream might contain more
      than one time slice. So depending how this is specified, the
      output file might be needed uppon restart.

*** Scheduling options
    Options for the scheduling system. In the xml configuration file,
    these have to be put under the machine specific node.
    - ~--run_time~ reserved time for run job (default: '24:00:00' on
      daint, '08:00:00' on mistral)
    - ~--transfer_time~ reserved time for transfer job (default:
      '02:00:00')
    - ~--archive_time~ reserved time for archive job (default:
      '03:00:00')

*** SLURM options
    Options specific to the SLURM scheduling system. In the xml
    configuration file, these have to be put under the machine
    specific node.
    - ~--account~ account to use for submitted job scripts (default:
      infered from $PROJECT on daint, None on mistral)
    - ~--partition~ queue to witch the run job gets submitted, mostly
      useful for debug (default: None).

*** Daint specific options
    - ~--modules_opt~ option for loading modules at run time. Either
      'switch', 'none' or 'purge' (default: switch)
    - ~--pgi_version~ specify pgi compiler version at run time (default: None)
    - ~--shebang~ run job script shebang (default: '#!/bin/bash')

*** Mistral specific options
    None so far

* Development
  In this section we describe a bit how the utility is implemented and
  how one can add options or support for a new machine.

* COSMO_CLM2_tools                                                 :noexport:
  - [ ] Add doc strings
** example_setup.xml
   #+BEGIN_SRC xml :tangle COSMO_CLM2_tools/example_setup.xml
     <?xml version="1.0" encoding="utf-8"?>
     <setup>
       <!-- main and machine specific options can also be set through the command line.
            Command line takes precedence -->
       <machine></machine>
       <main>
         <name>COSMO_CLM2</name>
         <install_dir></install_dir>
         <archive_dir></archive_dir>
         <cosmo_only></cosmo_only>
         <start_date></start_date>
         <end_date></end_date>
         <run_length></run_length>
         <cos_in>./COSMO_input</cos_in>
         <cos_nml>./COSMO_nml</cos_nml>
         <cos_exe>./cosmo</cos_exe>
         <cesm_in>./CESM_input</cesm_in>
         <cesm_nml>./CESM_nml</cesm_nml>
         <cesm_exe>./cesm.exe</cesm_exe>
         <oas_in>./OASIS_input</oas_in>
         <oas_nml>./OASIS_nml</oas_nml>
         <ncosx type="int"></ncosx>
         <ncosy type="int"></ncosy>
         <ncosio type="int"></ncosio>
         <ncesm type="int"></ncesm>
         <gpu_mode type="py_eval">False</gpu_mode>
         <dummy_day type="py_eval">False</dummy_day>
         <transfer_all type="py_eval">False</transfer_all>
         <input_type>file</input_type>
       </main>
       <daint>
         <account></account>
         <partition></partition>
         <modules_opt>switch</modules_opt>
         <pgi_version></pgi_version>
         <shebang>#!/bin/bash</shebang>
         <run_time>24:00:00</run_time>
         <transfer_time>02:00:00</transfer_time>
         <archive_time>03:00:00</archive_time>
       </daint>
       <mistral>
         <account></account>
         <partition></partition>
         <run_time>10:00:00</run_time>
       </mistral>
       <!-- Any namelist parameter can be changed by adding a <change_par> node directly under the <setup> node
            with attributes following this example
            <change_par file="INPUT_ORG" block="runctl" param="lreproduce" type="py_eval">True</change_par>
            - The value of the node is the new value of the namelist parameter
            - don't give the namelist file path, only the file name is needed.
            - type attribute can be any of the valid python types or "py_eval", in which case python
              will interpret the value. the default type is string
            - an "n" attribute starting at 1 (not 0) can also be given to target one of several blocks
              sharing the same name in a namelist, e.g. "gribout" blocks in INPUT_IO.
       -->
       <!-- In the same way, any namelist parameter can be deleted by adding an
            empty <del_par> node directly under the <setup> node with attributes following this example
            <del_par file="INPUT_ORG" block="runctl" param="lreproduce" />
            - don't give the namelist file path, only the file name is needed.
            - an "n" attribute starting at 1 (not 0) can also be given to target one of several blocks
              sharing the same name in a namelist, e.g. "gribout" blocks in INPUT_IO.
            - Obviouly any value given to that node is ignored
       -->
     </setup>
   #+END_SRC
** cc2_case.py
   :PROPERTIES:
   :header-args: :tangle COSMO_CLM2_tools/cc2_case.py :comments no
   :END:
*** preamble
    #+BEGIN_SRC python
      from __future__ import print_function
      from .tools import date_fmt, add_time_from_str, COSMO_input_file_name, indent_xml
      from subprocess import check_call, check_output
      from argparse import ArgumentParser, RawTextHelpFormatter
      import f90nml
      from datetime import datetime, timedelta
      import os
      import re
      import xml.etree.ElementTree as ET
      from glob import glob
      import shutil
      import time
      import sys

      available_cases = {}
    #+END_SRC
*** case factory function
    #+BEGIN_SRC python
      def factory(machine, **case_args):
          if machine not in available_cases:
              raise ValueError("machine {:s} not available".format(machine))
          else:
              return available_cases[machine](**case_args)
    #+END_SRC
*** available case decorator
    #+BEGIN_SRC python
      def available(cls):
          if cls._target_machine is None:
              raise NotImplementedError("_target_machine class variable not set for Class {:s}".format(cls.__name__))
          else:
              available_cases[cls._target_machine] = cls
              return cls
    #+END_SRC

*** cc2_case (base) class
    #+BEGIN_SRC python
      class cc2_case(object):
          """Base class defining a COSMO-CLM2 case"""

          _target_machine = None
          _n_tasks_per_node = None
          _default_install_dir = None
          _control_job = 'cc2_control_job'
          _run_job = 'cc2_run_job'
          _transfer_job = 'cc2_transfer_job'
          _archive_job = 'cc2_archive_job'
          _xml_config = 'cc2_config.xml'
          _transfer_list = 'cc2_transfer_list'
          NotImplementedMessage = "required method {:s} not implemented by class {:s}.\n" \
                                  "Implement with a single pass statement if irrelevant to this machine."


          def __init__(self, name='COSMO_CLM2', install_dir=None, install=False,
                       cos_nml='./COSMO_nml', cos_in='./COSMO_input', cos_exe='./cosmo', cos_rst=None,
                       cesm_nml='./CESM_nml', cesm_in='./CESM_input', cesm_exe='./cesm.exe', cesm_rst=None,
                       oas_in='./OASIS_input', oas_nml='./OASIS_nml', archive_dir=None,
                       start_date=None, end_date=None, run_length=None,
                       ncosx=None, ncosy=None, ncosio=None, ncesm=None,
                       gpu_mode=False, dummy_day=True, cosmo_only=False, gen_oasis=False,
                       input_type='file', transfer_all=True,
                       archive_per_month=False, archive_compression='none', archive_cesm=True, archive_rm=False,
                       start_mode='startup', restart_date=None):

              # Basic init (no particular work required)
              self.name = name
              self.run_length = run_length
              self.gpu_mode = gpu_mode
              self.dummy_day = dummy_day
              self.cosmo_only = cosmo_only
              self.gen_oasis = gen_oasis
              self.cos_in = os.path.abspath(cos_in)
              self.install = install
              self.input_type = input_type
              self.transfer_all = transfer_all
              self.archive_dir = None if archive_dir is None else os.path.abspath(archive_dir)
              self.archive_per_month = archive_per_month
              self.archive_compression = archive_compression
              self.archive_cesm = archive_cesm
              self.archive_rm = archive_rm
              self.transfer_by_chunck = not self.transfer_all and self.input_type == 'file'
              self.start_mode = start_mode
              # Create namelists dictionnary
              self.nml = nmldict(self)
              # Set install_dir and path
              self.install_dir = install_dir
              # Install: transfer namelists, executables and input files
              if self.install:
                  log = 'Setting up case {:s} in {:s}'.format(self.name, self._path)
                  print(log + '\n' + '-' * len(log))
                  self.install_case(cos_nml, cos_in, cos_exe, cos_rst, cesm_nml, cesm_in, cesm_exe, cesm_rst, oas_nml, oas_in)
                  self.create_missing_dirs()
              self.cos_exe = cos_exe
              if not self.cosmo_only:
                  self.cesm_exe = cesm_exe
              # Settings involving namelist changes
              self.start_date = start_date
              self.restart_date = restart_date
              self.end_date = end_date
              self.set_nml_start_parameters()
              # - ML - Some of the following is useless for transfer and archive actions
              self._compute_run_dates()   # defines _run_start_date, _run_end_date and _runtime (_end_date if needed)
              self._apply_run_dates()   # put dates and runtime in namelists objects (writing to file at the end)
              self._check_INPUT_IO()
              self._organize_tasks(ncosx, ncosy, ncosio, ncesm)
              # Finish install
              if self.install:
                  self._build_run_job()
                  if self.transfer_by_chunck and self._run_end_date < self.end_date:
                      self._build_transfer_job()
                  if self.archive_dir is not None:
                      self._build_archive_job()
                  self.to_xml()
                  self.install_input()
              # Write modified namelists to file
              self.write_open_nml()

          @property
          def cos_exe(self):
              return self._cos_exe
          @cos_exe.setter
          def cos_exe(self, exe_path):
              self._cos_exe = os.path.basename(exe_path)

          @property
          def cesm_exe(self):
              return self._cesm_exe
          @cesm_exe.setter
          def cesm_exe(self, exe_path):
              self._cesm_exe = os.path.basename(exe_path)

          @property
          def install_dir(self):
              return self._install_dir
          @install_dir.setter
          def install_dir(self, ins_dir):
              if ins_dir is None:
                  if self._default_install_dir is None:
                      raise NotImplementedError("_default_install_dir class variable not set for Class {:s}".format(cls.__name__))
                  else:
                      self._install_dir = self._default_install_dir
              else:
                  self._install_dir = ins_dir
              # Make install_dir absolute
              self._install_dir = os.path.abspath(self._install_dir)
              # Set case path
              self._path = os.path.join(self._install_dir, self.name)

          @property
          def path(self):
              return self._path

          @property
          def start_date(self):
              return self._start_date
          @start_date.setter
          def start_date(self, start_date):
              if start_date is not None:
                  self._start_date = datetime.strptime(start_date, date_fmt['in'])
                  self.nml['INPUT_ORG']['runctl']['ydate_ini'] = self._start_date.strftime(date_fmt['cosmo'])
              elif 'ydate_ini' in self.nml['INPUT_ORG']['runctl']:
                  self._start_date = datetime.strptime(self.nml['INPUT_ORG']['runctl']['ydate_ini'],
                                                       date_fmt['cosmo'])
              else:
                  raise ValueError("ydate_ini has to be given in INPUT_ORG/runctl if no start_date is provided")

          @property
          def restart_date(self):
              return self._restart_date
          @restart_date.setter
          def restart_date(self, restart_date):
              if restart_date is not None:
                  self._restart_date = datetime.strptime(restart_date, date_fmt['in'])
              else:
                  self._restart_date = None

          @property
          def end_date(self):
              return self._end_date
          @end_date.setter
          def end_date(self, end_date):
              if end_date is not None:
                  self._end_date = datetime.strptime(end_date, date_fmt['in'])
                  self.nml['INPUT_ORG']['runctl']['ydate_end'] = self._end_date.strftime(date_fmt['cosmo'])
              elif 'ydate_end' in self.nml['INPUT_ORG']['runctl']:
                  self._end_date = datetime.strptime(self.nml['INPUT_ORG']['runctl']['ydate_end'], date_fmt['cosmo'])
              else:
                  self._end_date = None

          @property
          def cos_in_file_size(self):
              status_node = ET.parse(os.path.join(self.path, self._xml_config)).getroot().find('status')
              return int(status_node.find('cos_in_file_size').text)
          @cos_in_file_size.setter
          def cos_in_file_size(self, sz):
              tree = ET.parse(os.path.join(self.path, self._xml_config))
              tree.find('status').find('cos_in_file_size').text = str(sz)
              tree.write(os.path.join(self.path, self._xml_config), xml_declaration=True)

          @property
          def run_status(self):
              status_node = ET.parse(os.path.join(self.path, self._xml_config)).getroot().find('status')
              return status_node.find('run_status').text
          @run_status.setter
          def run_status(self, status):
              tree = ET.parse(os.path.join(self.path, self._xml_config))
              tree.find('status').find('run_status').text = status
              tree.write(os.path.join(self.path, self._xml_config), xml_declaration=True)

          @property
          def transfer_status(self):
              status_node = ET.parse(os.path.join(self.path, self._xml_config)).getroot().find('status')
              return status_node.find('transfer_status').text
          @transfer_status.setter
          def transfer_status(self, status):
              tree = ET.parse(os.path.join(self.path, self._xml_config))
              tree.find('status').find('transfer_status').text = status
              tree.write(os.path.join(self.path, self._xml_config), xml_declaration=True)


          def install_case(self, cos_nml, cos_in, cos_exe, cos_rst, cesm_nml, cesm_in, cesm_exe, cesm_rst, oas_nml, oas_in):

              if not os.path.exists(self.path):
                  # Create case directory
                  os.makedirs(self.path)

              # Transfer everything except COSMO input files
              check_call(['rsync', '-avrL', os.path.abspath(cos_nml)+'/', self.path])
              check_call(['rsync', '-avrL', os.path.abspath(cos_exe), self.path])
              if not self.cosmo_only:
                  if self.input_type == 'symlink':
                      check_call(['ln', '-sf', os.path.abspath(cesm_in), os.path.join(self.path,'CESM_input')])
                  elif self.input_type == 'file':
                      check_call(['rsync', '-avrL', os.path.abspath(cesm_in)+'/', os.path.join(self.path,'CESM_input')+'/'])
                  check_call(['rsync', '-avrL', os.path.abspath(cesm_nml)+'/', self.path])
                  check_call(['rsync', '-avrL', os.path.abspath(cesm_exe), self.path])
                  if not self.gen_oasis:
                      if self.input_type == 'symlink':
                          check_call(['ln', '-sf', os.path.abspath(oas_in), self.path])
                      elif self.input_type == 'file':
                          check_call(['rsync', '-avrL', os.path.abspath(oas_in)+'/', self.path])
                  else:
                      print('generate OASIS file:')
                      for f in os.listdir(oas_in):
                          try:
                              print('   removing ' +  os.path.join(self.path, f))
                              os.remove(os.path.join(self.path, f))
                          except OSError:
                              pass
                  check_call(['rsync', '-avrL', os.path.abspath(oas_nml)+'/', self.path])

              if self.start_mode != 'startup':
                  if 'ydir_restart_in' in self.nml['INPUT_IO']['ioctl']:
                      cos_rst_nml = self.nml['INPUT_IO']['ioctl']['ydir_restart_in']
                  elif 'ydir_restart' in  self.nml['INPUT_IO']['ioctl']:
                      cos_rst_nml = self.nml['INPUT_IO']['ioctl']['ydir_restart']
                  else:
                      cos_rst_nml = ''
                  self._mk_miss_path(cos_rst_nml)
                  cos_rst_target = os.path.normpath(os.path.join(self.path, cos_rst_nml, os.path.basename(cos_rst)))
                  check_call(['rsync', '-avL', cos_rst, cos_rst_target])

                  if cos_rst.endswith('.gz'):
                      check_call(['gunzip', cos_rst_target])
                  elif cos_rst.endswith('.bz2'):
                      check_call(['bzip2', cos_rst_target])

                  if cesm_rst.endswith('.tar'):
                      check_call(['tar', '-xvf', cesm_rst, '-C', self.path])
                  elif cesm_rst.endswith(('.tgz', '.tar.gz')):
                      check_call(['tar', '-zxvf', cesm_rst, '-C', self.path])
                  elif cesm_rst.endswith(('.tbz', '.tar.bz2')):
                      check_call(['tar', '-jxvf', cesm_rst, '-C', self.path])
                  else:
                      check_call(['rsync', '-avL', cesm_rst_origin+'/', self.path])

              # Set case name in namelist
              self.nml['drv_in']['seq_infodata_inparm']['case_name'] = self.name


          def set_nml_start_parameters(self):

              if self.start_mode == 'startup':
                  self.nml['INPUT_ORG']['runctl']['hstart'] = 0
                  if not self.cosmo_only:
                      self.nml['drv_in']['seq_infodata_inparm']['start_type'] = 'startup'
                      self.nml['drv_in']['seq_timemgr_inparm']['start_ymd'] = int(self.start_date.strftime(date_fmt['cesm']))
              else:
                  self.nml['INPUT_ORG']['runctl']['hstart'] = (self.restart_date - self.start_date).total_seconds() // 3600.0
                  if not self.cosmo_only:
                      if self.start_mode == 'continue':
                          self.nml['drv_in']['seq_infodata_inparm']['start_type'] = 'continue'
                      elif self.start_mode == 'restart':
                          self.nml['drv_in']['seq_infodata_inparm']['start_type'] = 'branch' 
                      self.nml['drv_in']['seq_timemgr_inparm']['start_ymd'] = int(self.restart_date.strftime(date_fmt['cesm']))


          def _cos_input_delta_ext(self):

              # Set time interval between 2 intput files
              delta = timedelta(hours=self.nml['INPUT_IO']['gribin']['hincbound'])
              # Set file extension
              ext = ''
              if 'yform_read' in self.nml['INPUT_IO']['ioctl']:
                  if self.nml['INPUT_IO']['ioctl']['yform_read'] == 'ncdf':
                      ext = '.nc'
              return delta, ext


          def build_transfer_list(self, start_date, end_date, initial=False):

              delta, ext = self._cos_input_delta_ext()

              # function to check and add file to transfer list or directly symlink
              def _check_add_file(root, date, file_list):
                  file_name = COSMO_input_file_name(root, date, ext)
                  if os.path.exists(os.path.join(self.cos_in, file_name)):
                      if self.input_type == 'symlink':
                          check_call(['ln', '-sf', os.path.join(self.cos_in, file_name),
                                      os.path.join(self.path,'COSMO_input')])
                      elif self.input_type == 'file':
                          file_list.write(file_name + '\n')
                  else:
                      raise ValueError("input file {:s} is missing from {:s}".format(file_name, self.cos_in))

              # Build file list to transfer or symlink
              with open(self._transfer_list, mode ='w') as t_list:
                  if initial:
                      _check_add_file('laf', start_date, t_list)
                  cur_date = start_date
                  while cur_date <= end_date:
                      _check_add_file('lbfd', cur_date, t_list)
                      cur_date += delta


          def transfer_input(self):

              if self.input_type == 'file':
                  check_call(['rsync', '-avrL', '--files-from', self._transfer_list,
                              self.cos_in+'/', os.path.join(self.path,'COSMO_input')])


          def install_input(self):

              # Get cosmo lbf input file size
              _, ext = self._cos_input_delta_ext()
              file_name = COSMO_input_file_name('lbfd', self.start_date, ext)
              file_path = os.path.join(self.cos_in, file_name)
              self.cos_in_file_size = os.stat(file_path).st_size

              # Create COSMO_input directory if missing (essentially for symlinks)
              self._mk_miss_path('COSMO_input')

              # Transfer first chunck input files or all
              initial = self.start_mode == 'startup'
              if self.transfer_by_chunck and self._run_end_date < self.end_date:
                  self.build_transfer_list(self._run_start_date, self._run_end_date, initial=initial)
              else:
                  end_date = self.end_date + timedelta(days=1) if self.dummy_day else self.end_date
                  self.build_transfer_list(self._run_start_date, end_date, initial=initial)
              self.transfer_input()
              os.remove(self._transfer_list)

              # Set transfer status
              self.transfer_status = 'complete'


          def _check_COSMO_input(self, start_date, end_date):

              delta, ext = self._cos_input_delta_ext()
              cur_date = start_date
              cos_in_file_size = self.cos_in_file_size # get from xml once for all
              while cur_date <= end_date:
                  file_name = COSMO_input_file_name('lbfd', cur_date, ext)
                  file_path = os.path.join(self.path, 'COSMO_input', file_name)
                  if not os.path.exists(file_path):
                      raise ValueError("COSMO input file {:s} missing".format(file_name))
                  fs = os.stat(file_path).st_size
                  if fs != cos_in_file_size:
                      err_mess = "COSMO input file {:s} has byte size {:d} instead of {:d}"
                      raise ValueError(err_mess.format(file_name, fs, cos_in_file_size))
                  cur_date += delta


          def _organize_tasks(self, ncosx, ncosy, ncosio, ncesm):

              # COSMO tasks
              # -----------
              if ncosx is None:
                  self._ncosx = self.nml['INPUT_ORG']['runctl']['nprocx']
              else:
                  self._ncosx = ncosx
                  self.nml['INPUT_ORG']['runctl']['nprocx'] = ncosx
              if ncosy is None:
                  self._ncosy = self.nml['INPUT_ORG']['runctl']['nprocy']
              else:
                  self._ncosy = ncosy
                  self.nml['INPUT_ORG']['runctl']['nprocy'] = ncosy
              if ncosio is None:
                  self._ncosio = self.nml['INPUT_ORG']['runctl']['nprocio']
              else:
                  self._ncosio = ncosio
                  self.nml['INPUT_ORG']['runctl']['nprocio'] = ncosio
              self._ncos = self._ncosx * self._ncosy + self._ncosio

              # CESM tasks and number of nodes
              # ------------------------------
              if self.cosmo_only:
                  self._ncesm = 0
                  if self.gpu_mode:
                      self._n_nodes = self._ncos
                  else:
                      self._n_nodes = self._ncos // self._n_tasks_per_node
              else:
                  if self.gpu_mode:   # Populate nodes with CESM tasks except one
                      self._n_nodes = self._ncos
                      self._ncesm = self._n_nodes * (self._n_tasks_per_node - 1)
                  else:   # Determine number of CESM tasks and deduce number of nodes
                      if ncesm is None:
                          self._ncesm = self.nml['drv_in']['ccsm_pes']['lnd_ntasks']
                      else:
                          self._ncesm = ncesm
                      ntot = self._ncos + self._ncesm
                      if ntot % self._n_tasks_per_node != 0:
                          msg = "total number of tasks (ncosx x ncosy + ncosio + ncesm = {:d}) has to be divisible by {:d}"
                          raise ValueError(msg.format(ntot, self._n_tasks_per_node))
                      self._n_nodes = ntot // self._n_tasks_per_node
                  # Apply number of CESM tasks to all relevant namelist parameters
                  for comp in ['atm', 'cpl', 'glc', 'ice', 'lnd', 'ocn', 'rof', 'wav']:
                      self.nml['drv_in']['ccsm_pes']['{:s}_ntasks'.format(comp)] = self._ncesm
                  if self.gen_oasis:
                      self.nml['drv_in']['ccsm_pes']['atm_ntasks'] = 1


          def _compute_run_dates(self):

              # Access to namelists
              # -------------------
              INPUT_ORG = self.nml['INPUT_ORG']
              if not self.cosmo_only:
                  drv_in = self.nml['drv_in']

              # Read in _run_start_date
              # -----------------------
              date_cosmo = self._start_date + timedelta(hours=INPUT_ORG['runctl']['hstart'])
              if not self.cosmo_only:
                  date_cesm = datetime.strptime(str(drv_in['seq_timemgr_inparm']['start_ymd']), date_fmt['cesm'])
                  if date_cosmo != date_cesm:
                      raise ValueError("start dates are not identical in COSMO and CESM namelists")
              self._run_start_date = date_cosmo

              # Compute _runtime and _run_end_date (possibly _end_date)
              # -------------------------------------------------------
              if self._end_date is not None:
                  if self._run_start_date >= self._end_date:
                      raise ValueError("run sart date >= case end date")
                  else:
                      if self.run_length is None:
                          self._run_end_date = self._end_date
                      else:
                          self._run_end_date = min(add_time_from_str(self._run_start_date, self.run_length),
                                                   self._end_date)
                      self._runtime = self._run_end_date - self._run_start_date
              else:
                  if self.run_length is None:
                      runtime_cosmo = (INPUT_ORG['runctl']['nstop'] + 1) * INPUT_ORG['runctl']['dt'] \
                                      - INPUT_ORG['runctl']['hstart'] * 3600.0
                      if not self.cosmo_only:
                          runtime_cesm = drv_in['seq_timemgr_inparm']['stop_n']
                          if runtime_cosmo != runtime_cesm:
                              raise ValueError("run lengths are not identical in COSMO and CESM namelists")
                      self._runtime = timedelta(seconds=runtime_cosmo)
                      self._run_end_date = self._run_start_date + self._runtime
                  else:
                      self._run_end_date = add_time_from_str(self._run_start_date, self.run_length)
                      self._runtime = self._run_end_date - self._run_start_date
                  self._end_date = self._run_end_date

              # Add a dummy day to the last chunk if required
              # ---------------------------------------------
              if self._run_end_date == self._end_date and self.dummy_day:
                  one_day = timedelta(days=1)
                  self._run_end_date += one_day
                  self._runtime += one_day


          def _apply_run_dates(self):

              # Access to namelists
              INPUT_ORG = self.nml['INPUT_ORG']
              INPUT_IO = self.nml['INPUT_IO']
              if not self.cosmo_only:
                  drv_in = self.nml['drv_in']

              # Compute times
              start_seconds = (self._run_start_date - self.start_date).total_seconds()
              dt = INPUT_ORG['runctl']['dt']
              runtime_seconds = self._runtime.total_seconds()
              runtime_hours = runtime_seconds // 3600

              hstart = start_seconds // 3600
              nstart = start_seconds // dt - 1
              hstop = hstart + runtime_hours
              nstop = (start_seconds + runtime_seconds) // dt


              # adapt INPUT_ORG
              if 'hstop' in INPUT_ORG['runctl']:
                  del INPUT_ORG['runctl']['hstop']
              INPUT_ORG['runctl']['nstop'] = nstop - 1
              if 'hstop' in INPUT_ORG['runctl']:
                  del INPUT_ORG['runctl']['hstop']

              # adapt INPUT_IO
              for gribout in self._get_gribouts():
                  if 'hcomb' in gribout:
                      gribout['hcomb'][0:2] = hstart, hstop
                  elif 'ncomb' in gribout:
                      gribout['ncomb'][0:2] = nstart, nstop
              if self._run_end_date > self.end_date:
                  # ensure restart for the real end date, not after the dummy day
                  INPUT_IO['ioctl']['nhour_restart'] = [int(hstop)-24, int(hstop)-24, 24]
              else:
                  INPUT_IO['ioctl']['nhour_restart'] = [int(hstop), int(hstop), 24]
            
              if not self.cosmo_only:
                  # adapt drv_in
                  drv_in['seq_timemgr_inparm']['stop_n'] = int(runtime_seconds)
                  if self._run_end_date > self.end_date:
                      # ensure restart for the real end date, not after the dummy day
                      drv_in['seq_timemgr_inparm']['restart_n'] = int(runtime_seconds)-86400
                  else:
                      drv_in['seq_timemgr_inparm']['restart_n'] = int(runtime_seconds)

                  # adapt namcouple
                  with open(os.path.join(self.path, 'namcouple_tmpl'), mode='r') as f:
                      content = f.read()
                  content = re.sub('_runtime_', str(int(runtime_seconds)), content)
                  with open(os.path.join(self.path, 'namcouple'), mode='w') as f:
                      f.write(content)


          def get_next_run_end_date(self):

              next_end_date = min(add_time_from_str(self._run_end_date, self.run_length),
                                  self.end_date)
              if next_end_date == self.end_date and self.dummy_day:
                  next_end_date += timedelta(days=1)

              return next_end_date


          def _check_INPUT_IO(self):

              # Make sure COSMO input and initial files are looked for in the COSMO_input folder
              self.nml['INPUT_IO']['gribin']['ydirini'] = 'COSMO_input'
              self.nml['INPUT_IO']['gribin']['ydirbd'] = 'COSMO_input'

              # Only keep gribout blocks that fit within runtime
              # (essentially to avoid crash for short tests)
              runtime_seconds = self._runtime.total_seconds()
              runtime_hours = runtime_seconds // 3600.0
              runtime_nstep = runtime_seconds // self.nml['INPUT_ORG']['runctl']['dt']
              gribouts_out = []
              gribouts_in = self._get_gribouts()
              for gribout in gribouts_in:
                  if 'hcomb' in gribout:
                      if runtime_hours >= gribout['hcomb'][2]:
                          gribouts_out.append(gribout)
                  elif 'ncomb' in gribout:
                      if runtime_nstep >= gribout['ncomb'][2]:
                          gribouts_out.append(gribout)
              if gribouts_out:
                  self.nml['INPUT_IO']['gribout'] = gribouts_out
                  self.nml['INPUT_IO']['ioctl']['ngribout'] = len(gribouts_out)
              else:
                  if gribouts_in:
                      del self.nml['INPUT_IO']['gribout']


          def _get_gribouts(self):

              if 'gribout' not in self.nml['INPUT_IO'].keys():
                  return []
              else:
                  gribouts = self.nml['INPUT_IO']['gribout']
                  if not isinstance(gribouts, list):
                      gribouts = [gribouts]
                  return gribouts


          def write_open_nml(self):
              self.nml.write_all()


          def create_missing_dirs(self):

              # COSMO
              # -----
              # input
              self._mk_miss_path(self.nml['INPUT_IO']['gribin']['ydirini'])
              self._mk_miss_path(self.nml['INPUT_IO']['gribin']['ydirbd'])
              # output
              for gribout in self._get_gribouts():
                  self._mk_miss_path(gribout['ydir'])
              if 'ydir_restart' in self.nml['INPUT_IO']['ioctl']:
                  self._mk_miss_path(self.nml['INPUT_IO']['ioctl']['ydir_restart'])
              if 'ydir_restart_in' in self.nml['INPUT_IO']['ioctl']:
                  self._mk_miss_path(self.nml['INPUT_IO']['ioctl']['ydir_restart_in'])
              if 'ydir_restart_out' in self.nml['INPUT_IO']['ioctl']:
                  self._mk_miss_path(self.nml['INPUT_IO']['ioctl']['ydir_restart_out'])

              # CESM
              # ----
              if not self.cosmo_only:
                  # timing
                  # remove if exists before creating
                  shutil.rmtree(os.path.join(self.path, self.nml['drv_in']['seq_infodata_inparm']['timing_dir']),
                                ignore_errors=True)
                  shutil.rmtree(os.path.join(self.path, self.nml['drv_in']['seq_infodata_inparm']['tchkpt_dir']),
                                ignore_errors=True)
                  self._mk_miss_path(self.nml['drv_in']['seq_infodata_inparm']['timing_dir'])
                  self._mk_miss_path(self.nml['drv_in']['seq_infodata_inparm']['tchkpt_dir'])
                  # input / output
                  for comp in ['atm', 'cpl', 'glc', 'ice', 'lnd', 'ocn', 'rof', 'wav']:
                      self._mk_miss_path(self.nml['{:s}_modelio.nml'.format(comp)]['modelio']['diri'])
                      self._mk_miss_path(self.nml['{:s}_modelio.nml'.format(comp)]['modelio']['diro'])


          def _mk_miss_path(self, rel_path):

              path = os.path.join(self.path, rel_path)
              if not os.path.exists(path):
                  print('Creating path ' + path)
                  os.makedirs(path)


          def to_xml(self):

              config_node = ET.Element('config')
              tree = ET.ElementTree(config_node)
              ET.SubElement(config_node, 'machine').text = self._target_machine

              main_node = ET.SubElement(config_node, 'main')
              ET.SubElement(main_node, 'name').text = self.name
              ET.SubElement(main_node, 'install_dir').text = self.install_dir
              ET.SubElement(main_node, 'cosmo_only', type='py_eval').text = str(self.cosmo_only)
              ET.SubElement(main_node, 'gen_oasis', type='py_eval').text = str(self.gen_oasis)
              ET.SubElement(main_node, 'run_length').text = self.run_length
              ET.SubElement(main_node, 'cos_exe').text = self.cos_exe
              if not self.cosmo_only:
                  ET.SubElement(main_node, 'cesm_exe').text = self.cesm_exe
              ET.SubElement(main_node, 'cos_in').text = self.cos_in
              ET.SubElement(main_node, 'archive_dir').text = self.archive_dir
              ET.SubElement(main_node, 'gpu_mode', type='py_eval').text = str(self.gpu_mode)
              ET.SubElement(main_node, 'dummy_day', type='py_eval').text = str(self.dummy_day)
              ET.SubElement(main_node, 'transfer_all', type='py_eval').text = str(self.transfer_all)
              ET.SubElement(main_node, 'start_mode').text = self.start_mode
              node = ET.SubElement(main_node, 'restart_date')
              if self.start_mode != 'startup':
                  node.text = self.restart_date.strftime(date_fmt['in'])

              status_node = ET.SubElement(config_node, 'status')
              ET.SubElement(status_node, 'run_status')
              ET.SubElement(status_node, 'transfer_status')
              ET.SubElement(status_node, 'cos_in_file_size')

              # - ML - Could be usefull in case machine specific arguments need to be stored one day.
              #        This isn't the case as of now
              ET.SubElement(config_node, self._target_machine)

              indent_xml(config_node)

              tree.write(os.path.join(self.path, self._xml_config), xml_declaration=True)


          def set_next_run(self):

              if self._run_end_date < self._end_date:
                  tree = ET.parse(os.path.join(self.path, self._xml_config))
                  main_node = tree.find('main')
                  main_node.find('start_mode').text = 'continue'
                  main_node.find('restart_date').text = self._run_end_date.strftime(date_fmt['in'])
                  tree.write(os.path.join(self.path, self._xml_config), xml_declaration=True)


          def submit_run(self):

              cwd = os.getcwd()
              os.chdir(self.path)

              self._submit_run_cmd(self._run_start_date, self._run_end_date)

              os.chdir(cwd)


          def submit_next_run(self):

              cwd = os.getcwd()
              os.chdir(self.path)

              self._submit_run_cmd(self._run_end_date, self.get_next_run_end_date())

              os.chdir(cwd)


          def submit_next_transfer(self):

              cwd = os.getcwd()
              os.chdir(self.path)

              next_end_date = self.get_next_run_end_date()
              self.build_transfer_list(self._run_end_date, next_end_date)
              self._submit_transfer_cmd(self._run_end_date, next_end_date)

              os.chdir(cwd)


          def submit_archive(self):

              cwd = os.getcwd()
              os.chdir(self.path)

              self._submit_archive_cmd()

              os.chdir(cwd)


          def run(self):

              # Monitor time
              start_time = time.time()

              # Clean workdir
              file_list = glob('YU*') + glob('debug*') + glob('core*') + glob('nout.*') + glob('*.timers_*')
              for f in file_list:
                  os.remove(f)

              # Check presence and size of input files for current chunk
              self._check_COSMO_input(self._run_start_date, self._run_end_date)

              # Run
              self._run_fun()

              # Monitor time
              elapsed = time.time() - start_time
              print("\nCase {name:s} ran in {elapsed:.2f}\n".format(name=self.name, elapsed=elapsed))


          def _build_run_job(self):
              """Place holder for _build_run_job method to be implemented by machine specific classes."""

              raise NotImplementedError(self.NotImplementedMessage.format('_build_run_job(self)', self.__class__.__name__))


          def _build_transfer_job(self):
              """Place holder for _build_transfer_job method to be implemented by machine specific classes."""

              raise NotImplementedError(self.NotImplementedMessage.format('_build_transfer_job(self)', self.__class__.__name__))


          def _build_archive_job(self):
              """Place holder for _build_archive_job method to be implemented by machine specific classes."""

              raise NotImplementedError(self.NotImplementedMessage.format('_build_archive_job(self)', self.__class__.__name__))


          def _run_fun(self):
              """Place holder for _run_fun method to be implemented by machine specific classes."""

              raise NotImplementedError(self.NotImplementedMessage.format('_run_fun(self)', self.__class__.__name__))


          def _submit_run_cmd(self):
              """Place holder for _submit_run_cmd method to be implemented by machine specific classes."""

              raise NotImplementedError(self.NotImplementedMessage.format('_submit_run_cmd(self)', self.__class__.__name__))


          def _submit_transfer_cmd(self):
              """Place holder for _submit_transfer_cmd method to be implemented by machine specific classes."""

              raise NotImplementedError(self.NotImplementedMessage.format('_submit_transfer_cmd(self)', self.__class__.__name__))


          def _submit_archive_cmd(self):
              """Place holder for _submit_archive_cmd method to be implemented by machine specific classes."""

              raise NotImplementedError(self.NotImplementedMessage.format('_submit_archive_cmd(self)', self.__class__.__name__))
    #+END_SRC
*** daint_case class
    #+BEGIN_SRC python
      @available
      class daint_case(cc2_case):
          """Class defining a COSMO-CLM2 case on Piz Daint"""

          _target_machine='daint'
          _n_tasks_per_node = 12
          _default_install_dir = os.path.normpath(os.environ['SCRATCH'])
          _archive_rst_job = 'cc2_archive_rst_job'


          def __init__(self, run_time='24:00:00', account=None, partition=None,
                       shebang='#!/bin/bash', modules_opt='switch', pgi_version=None,
                       transfer_time='02:00:00', archive_time='03:00:00', **base_case_args):

              self.run_time = run_time
              self.transfer_time = transfer_time
              self.archive_time = archive_time
              self.account = account
              self.modules_opt = modules_opt
              self.pgi_version = pgi_version
              self.shebang = shebang
              self.partition = partition
              cc2_case.__init__(self, **base_case_args)
              if self.install:
                  if not self.cosmo_only:
                      self._build_proc_config()
                  self.update_xml_config()


          @property
          def account(self):
              return self._account
          @account.setter
          def account(self, acc):
              if acc is None:
                  # Guess from ${PROJECT} environment variable
                  self._account = os.path.normpath(os.environ['PROJECT']).split(os.path.sep)[-2]
              else:
                  self._account = acc


          def update_xml_config(self):
              tree = ET.parse(os.path.join(self.path, self._xml_config))
              daint_node = tree.find('daint')
              ET.SubElement(daint_node, 'archive_per_month', type='py_eval').text = str(self.archive_per_month)
              indent_xml(tree.getroot())
              tree.write(os.path.join(self.path, self._xml_config), xml_declaration=True)


          def _build_run_job(self):

              # Header
              # ------
              script_str = '{:s}\n\n'.format(self.shebang)
              script_str += '#SBATCH --constraint=gpu\n'
              script_str += '#SBATCH --job-name={:s}\n'.format(self.name)
              script_str += '#SBATCH --nodes={:d}\n'.format(self._n_nodes)
              script_str += '#SBATCH --account={:s}\n'.format(self.account)
              script_str += '#SBATCH --time={:s}\n'.format(self.run_time)
              script_str += '#SBATCH --gres=gpu:1\n'
              if self.partition is not None:
                  script_str += '#SBATCH --partition={:s}\n'.format(self.partition)

              # environment variables
              # ---------------------
              script_str +='''
      export MALLOC_MMAP_MAX_=0
      export MALLOC_TRIM_THRESHOLD_=536870912

      # Set this to avoid segmentation faults
      ulimit -s unlimited
      ulimit -a

      export OMP_NUM_THREADS=1
      '''
              if self.gpu_mode:
                  script_str += '''
      # Use for gpu mode
      export MV2_ENABLE_AFFINITY=0
      export MV2_USE_CUDA=1
      export MPICH_G2G_PIPELINE=256
      '''
                  if self.cosmo_only:
                      script_str += 'export MPICH_RDMA_ENABLED_CUDA=1\n'

              # Modules
              # -------
              script_str += '\n'
              if self.modules_opt != 'none':
                  # pgi programing environment
                  if self.modules_opt == 'purge':
                      script_str += 'module purge\n'
                      script_str += 'module load PrgEnv-pgi\n'
                  elif self.modules_opt == 'switch':
                      script_str += 'module switch PrgEnv-cray PrgEnv-pgi\n'
                  # pgi version
                  if self.pgi_version is not None:
                      script_str += 'module unload pgi\n'
                      script_str += 'module load pgi/{:s}\n'.format(self.pgi_version)

                  # other modules
                  script_str += 'module load daint-gpu\n'
                  script_str += 'module load cray-netcdf\n'
                  if self.gpu_mode:
                      script_str += 'module load craype-accel-nvidia60\n'
                  script_str += '\n'

              # launch case
              # -----------
              script_str += 'cc2_control_case ./{:s}'.format(self._xml_config)

              # Write to file
              # -------------
              with open(os.path.join(self.path, self._run_job), mode='w') as script:
                  script.write(script_str)


          def _submit_run_cmd(self, d1, d2):

              d1_str = d1.strftime(date_fmt['cesm'])
              d2_str = d2.strftime(date_fmt['cesm'])
              logfile = '{:s}_{:s}-{:s}.out'.format(self.name, d1_str, d2_str)

              cmd_tmpl = 'sbatch --output={log:s} --error={log:s} {job:s}'
              cmd = cmd_tmpl.format(log=logfile, job=self._run_job)
              print("submitting run with check_call('" + cmd + "', shell=True)")
              check_call(cmd, shell=True)


          def _build_transfer_job(self):

              # Header
              # ------
              script_str = '#!/bin/bash -l\n\n'
              script_str += '#SBATCH --partition=xfer\n'
              script_str += '#SBATCH --ntasks=1\n'
              script_str += '#SBATCH --time={:s}\n'.format(self.transfer_time)
              script_str += '#SBATCH --job-name=cc2_transfer\n\n'

              # Case dependent variables
              # ------------------------
              script_str += '# Case dependent variables\n'
              script_str += '# ------------------------\n'
              script_str += 'run_job={:s}\n'.format(self._run_job)
              script_str += 'xml_config={:s}\n'.format(self._xml_config)
              script_str += 'cos_in_origin={:s}\n'.format(self.cos_in)
              script_str += 'cos_in_target={:s}\n'.format(os.path.join(self.path,'COSMO_input'))
              script_str += 'transfer_list={:s}\n'.format(self._transfer_list)

              # Main script
              # -----------
              # Use sed commands to handle case status as python isn't available on the xfer queue.
              # Otherwise just use cc2_control --action=transfer
              script_str += '''
      # Functions to get and set case status
      # ------------------------------------
      get_status(){
          sed -n 's@\s*<'$1'_status>\(.*\)</'$1'_status>@\\1@p' ${xml_config}
      }
      set_status(){
          sed -i 's@\(\s*<'$1'_status>\).*\(</'$1'_status>\)@\\1'$2'\\2@' ${xml_config}
      }

      # Set transfer status
      # -------------------
      set_status "transfer" "transferring"

      # Transfer
      # --------
      rsync -avrL --files-from ${transfer_list} ${cos_in_origin} ${cos_in_target}

      # Submit next run
      # ---------------
      if [[ $(get_status "run") == "complete" ]]; then
          set_status "run" "submitted"
          unset SLURM_MEM_PER_CPU
          sbatch --output $1 --error $1 ${run_job}
      fi

      # Set transfer status
      # -------------------
      set_status "transfer" "complete"'''

              # Write to file
              # -------------
              with open(os.path.join(self.path, self._transfer_job), mode='w') as script:
                  script.write(script_str)


          def _submit_transfer_cmd(self, d1, d2):

              d1_str = d1.strftime(date_fmt['cesm'])
              d2_str = d2.strftime(date_fmt['cesm'])
              logfile = 'transfer_{:s}-{:s}.out'.format(d1_str, d2_str)
              run_log = '{:s}_{:s}-{:s}.out'.format(self.name, d1_str, d2_str)

              cmd_tmpl = 'sbatch --output={log:s} --error={log:s} {job:s} {run_log:s}'
              cmd = cmd_tmpl.format(log=logfile, job=self._transfer_job, run_log=run_log)
              print("submitting transfer with check_call('" + cmd + "', shell=True)")
              check_call(cmd, shell=True)


          def _build_archive_job(self):

              # Build archive job for output files
              # ==================================

              # Header
              # ------
              script_str = '#!/bin/bash -l\n\n'
              script_str += '#SBATCH --partition=xfer\n'
              script_str += '#SBATCH --ntasks=1\n'
              script_str += '#SBATCH --time={:s}\n'.format(self.archive_time)
              script_str += '#SBATCH --job-name=cc2_archive\n\n'

              # Case dependent variables
              # ------------------------
              script_str += '# Case dependent variables\n'
              script_str += '# ------------------------\n'
              script_str += 'CASE_NAME={:s}\n'.format(self.name)
              script_str += 'archive_dir={:s}\n'.format(os.path.join(self.archive_dir, self.name))
              script_str += 'archive_cesm={:s}\n'.format('true' if self.archive_cesm else 'false')
              # COSMO output streams
              stream_list = ['"{:s}"'.format(os.path.normpath(gribout['ydir'])) for gribout in self._get_gribouts()]
              script_str += 'COSMO_gribouts=({:s})\n'.format(' '.join(stream_list))
              # CESM output streams
              stream_list = ['"h0"']
              for k in range(2,7):
                 if 'hist_fincl{:d}'.format(k) in self.nml['lnd_in']['clm_inparm']:
                     stream_list += ['"h{:d}"'.format(k-1)]
              script_str += 'CESM_hh=({:s})\n'.format(' '.join(stream_list))
              # Archiving options
              script_str += 'remove_originals={:s}\n'.format('true' if self.archive_rm else 'false')
              script_str += 'compression={:s}\n'.format(self.archive_compression)

              # Main script
              # -----------
              script_str += '''
      # Extract date components
      # -----------------------
      YS="${1:0:4}"
      MS=$(echo "${1:4:2}" | sed 's/^0*//')
      YE="${2:0:4}"
      ME=$(echo "${2:4:2}" | sed 's/^0*//')

      # Archiving options
      # -----------------
      if [[ ${compression} == "gzip" ]]; then
          tar_ext="tar.gz"
          tar_opt="zcf"
      elif [[ ${compression} == "bzip2" ]]; then
          tar_ext="tar.bz2"
          tar_opt="jcf"
      else
          tar_ext="tar"
          tar_opt="cf"
      fi

      if [[ ${remove_originals} == "true" ]]; then
          tar_rm='--remove-files'
      else
          tar_rm=''
      fi

      # Proceed to archiving
      # --------------------
      mkdir -p ${archive_dir}/COSMO_output
      mkdir -p ${archive_dir}/CESM_output

      for ((YYYY=YS; YYYY<=YE; YYYY++)); do
          echo "treating year ${YYYY}"
          if [[ $YYYY == $YS ]]; then m1=$MS; else m1=01; fi
          if [[ $YYYY == $YE ]]; then m2=$ME; else m2=12; fi
          for ((m=m1; m<=m2; m++)); do
              echo "    treating month ${m}"
              # Archive COSMO output
              if ((${#COSMO_gribouts[@]} > 0)); then
                  YYYYMM=${YYYY}$(printf "%02d" ${m})
                  YYYYMMp1=$((YYYY + m/12))$(printf "%02d" $((m%12+1)))
                  for gribout in ${COSMO_gribouts[@]}; do
                      echo "        handling COSMO stream ${gribout}"
                      gribname=$(basename ${gribout})
                      arch_name=lffd${YYYYMM}.${tar_ext}
                      files=$(find ${gribout} \( \( -name "lffd${YYYYMM}"'*' -and -not -name "lffd${YYYYMM}0100"'*' \)\\
                                   -or -name "lffd${YYYYMMp1}0100"'*' \) -printf '%f\\n' | sort)
                      if (( ${#files} > 0 )); then
                          echo "            preparing ${arch_name}"
                          tar -${tar_opt} ${arch_name} -C ${gribout} ${files} ${tar_rm}
                          mkdir -p ${archive_dir}/COSMO_output/${gribname}
                          echo "            sending ${arch_name} to archive directory"
                          rsync -ar ${arch_name} ${archive_dir}/COSMO_output/${gribname} --remove-source-files
                      fi
                  done
              fi
              # Archive CESM output
              if [[ ${#CESM_hh[@]} > 0 && ${archive_cesm} == "true" ]]; then
                  YYYYMM=${YYYY}-$(printf "%02d" ${m})
                  for hh in ${CESM_hh[@]}; do
                      echo "        handling CESM stream ${hh}"
                      arch_name=${CASE_NAME}.clm2.${hh}.${YYYYMM}.${tar_ext}
                      files=$(find . -name "${CASE_NAME}.clm2.${hh}.${YYYYMM}"'*' -printf '%f\\n' | sort)
                      if (( ${#files} > 0 )); then
                          echo "            preparing ${arch_name}"
                          tar -${tar_opt} ${arch_name} ${files} ${tar_rm}
                          mkdir -p ${archive_dir}/CESM_output/${hh}
                          echo "            sending ${arch_name} to archive directory"
                          rsync -ar ${arch_name} ${archive_dir}/CESM_output/${hh} --remove-source-files
                      fi
                  done
              fi
          done
      done'''

              # Write to file
              # -------------
              with open(os.path.join(self.path, self._archive_job), mode='w') as script:
                  script.write(script_str)

              # Build archive job for restart files
              # ===================================

              # Header
              # ------
              script_str = '#!/bin/bash -l\n\n'
              script_str += '#SBATCH --partition=xfer\n'
              script_str += '#SBATCH --ntasks=1\n'
              script_str += '#SBATCH --time={:s}\n'.format(self.archive_time)
              script_str += '#SBATCH --job-name=cc2_archive_rst\n\n'

              # Case dependent variables
              # ------------------------
              script_str += '# Case dependent variables\n'
              script_str += 'CASE_NAME={:s}\n'.format(self.name)
              script_str += 'archive_dir={:s}\n'.format(os.path.join(self.archive_dir, self.name))
              if 'ydir_restart' in self.nml['INPUT_IO']['ioctl']:
                  COSMO_restart_dir = self.nml['INPUT_IO']['ioctl']['ydir_restart']
              elif 'ydir_restart_in' in self.nml['INPUT_IO']['ioctl']:
                  COSMO_restart_dir = self.nml['INPUT_IO']['ioctl']['ydir_restart_in']
              else:
                  COSMO_restart_dir = '.'
              script_str += 'COSMO_restart_dir={:s}\n\n'.format(COSMO_restart_dir)
              script_str += 'compression={:s}\n'.format(self.archive_compression)

              # Main script
              # -----------
              script_str += '''
      # Extract date components
      # -----------------------
      YYYY="${1:0:4}"
      MM="${1:4:2}"
      DD="${1:6:2}"
      HH="${1:8:2}"


      # Archive COSMO restart file
      # --------------------------
      echo "handling COSMO restart file"
      cd ${COSMO_restart_dir}
      rst_file=lrfd${YYYY}${MM}${DD}${HH}o

      # Compress rstart file
      echo "    compressing ${rst_file} if needed"
      if [[ ${compression} == "none" ]]; then
          transfer_file=${rst_file}
      elif [[ ${compression} == "gzip" ]]; then
          transfer_file=${rst_file}.gz
          gzip < ${rst_file} > ${transfer_file}
      elif [[ ${compression} == "bzip2" ]]; then
          transfer_file=${rst_file}.bz2
          bzip2 < ${rst_file} > ${transfer_file}
      fi

      # Transfer file
      target_dir=${archive_dir}/COSMO_output/restart
      mkdir -p ${target_dir}
      echo "    sending ${transfer_file} to ${target_dir}"
      rsync -ar ${transfer_file} ${target_dir}
      if [[ $? == 0 && ${compression} != "none" ]]; then rm -f ${transfer_file}; fi

      cd - > /dev/null


      # Archive CESM restart files
      # --------------------------
      echo "handling CESM restart files"
      date=${YYYY}-${MM}-${DD}-$(printf "%05d" $(( ${HH} * 3600 )) )
      tar_name=restart_${date}.tar

      # Generate rpointer files
      echo "    generating rpointer files"
      tmp_dir=tmp_archive_rst_${date}
      mkdir -p ${tmp_dir}

      printf "%s\n%s" ${CASE_NAME}.datm.r.${date}.nc ${CASE_NAME}.datm.rs1.${date}.bin > ${tmp_dir}/rpointer.atm
      echo "${CASE_NAME}.clm2.r.${date}.nc" > ${tmp_dir}/rpointer.lnd
      echo "${CASE_NAME}.cpl.r.${date}.nc" > ${tmp_dir}/rpointer.drv

      # Start archive with rpointer files
      echo "    building ${tar_name}"
      tar -cf ${tar_name} -C ${tmp_dir} rpointer.*

      rm -rf ${tmp_dir}

      # Add CESM restart files
      files=$( find \( -path "./${CASE_NAME}.clm2.rh[0-6].${date}.nc"\\
                    -or -path "./${CASE_NAME}.clm2.r.${date}.nc"\\
                    -or -path "./${CASE_NAME}.cpl.r.${date}.nc"\\
                    -or -path "./${CASE_NAME}.datm.rs1.${date}.bin" \)\\
                    -printf '%f\\n' | sort )
      tar -rf ${tar_name} ${files}

      # Compress archive
      echo "    compressing ${tar_name} if needed"
      if [[ ${compression} == "gzip" ]]; then
          transfer_name=${tar_name}.gz
          gzip < ${tar_name} > ${transfer_name} && rm ${tar_name}
      elif [[ ${compression} == "bzip2" ]]; then
          transfer_name=${tar_name}.bz2
          bzip2 < ${tar_name} > ${transfer_name} && rm ${tar_name}
      else
          transfer_name=${tar_name}
      fi

      # Transer archive
      target_dir=${archive_dir}/CESM_output/restart
      mkdir -p ${target_dir}
      echo "    transferring ${transfer_name} to ${target_dir}"
      rsync -ar ${transfer_name} ${target_dir} --remove-source-files'''

              # Write to file
              # -------------
              with open(os.path.join(self.path, self._archive_rst_job), mode='w') as script:
                  script.write(script_str)


          def _submit_archive_cmd(self):

              # Submit output archive job(s)
              # ============================
              def _assemble_cmd_and_submit(d1, d2):
                  d1_str, d2_str = d1.strftime('%Y%m'), d2.strftime('%Y%m')
                  cmd_tmpl = 'sbatch --output={log:s} --error={log:s} {job:s} {d1:s} {d2:s}'
                  logfile = '{:s}_{:s}-{:s}.out'.format('archive', d1_str, d2_str)
                  cmd = cmd_tmpl.format(job=self._archive_job, d1=d1_str, d2=d2_str, log=logfile)
                  print("submitting archive with check_call('" + cmd + "', shell=True)")
                  check_call(cmd, shell=True)

              # Shift archiving period vs run period by 1 month except first and last chunks
              # (last COSMO output files written at the sart of next chunk)
              start_archive_date = max(self.start_date, add_time_from_str(self._run_start_date, '-1m'))
              if self._run_end_date >= self.end_date:
                  end_archive_date = self.end_date
              else:
                  end_archive_date = max(self.start_date, add_time_from_str(self._run_end_date, '-1m'))

              if self.archive_per_month:
                  # Submit one archive job per month
                  cur_start_date = start_archive_date
                  while cur_start_date < end_archive_date:
                      cur_month_beg = datetime(cur_start_date.year, cur_start_date.month, 1)
                      tmp_date = add_time_from_str(cur_start_date, '1m')
                      cur_month_end = datetime(tmp_date.year, tmp_date.month, 1)
                      # Check that the we have to proceed to archiving for that period
                      if cur_month_end <= end_archive_date or end_archive_date >= self.end_date:
                          # Determine date for archive job and submit
                          _assemble_cmd_and_submit(cur_month_beg, cur_month_beg)
                      # Shift dates
                      cur_start_date = cur_month_end
              else:
                  # Submit the whole archiving period as one job
                  proceed = False
                  # Determine dates for archive job
                  if end_archive_date >= self.end_date:
                      d1 = datetime(start_archive_date.year, start_archive_date.month, 1)
                      d2 = datetime(end_archive_date.year, end_archive_date.month, 1)
                      if d2 == end_archive_date:
                          d2 = add_time_from_str(end_archive_date, '-1m')
                      proceed = True
                  else:
                      tmp_date = add_time_from_str(start_archive_date, '1m')
                      first_month_end = datetime(tmp_date.year, tmp_date.month, 1)
                      if end_archive_date >= first_month_end:
                          d1 = datetime(start_archive_date.year, start_archive_date.month, 1)
                          tmp_date = add_time_from_str(end_archive_date, '-1m')
                          d2 = datetime(tmp_date.year, tmp_date.month, 1)
                          proceed = True
                  if proceed:
                      # Submit archive job
                      _assemble_cmd_and_submit(d1, d2)

              # Submit restart archive job
              # ==========================
              end_date = min(self._run_end_date, self.end_date)
              end_date_str = end_date.strftime(date_fmt['cosmo'])
              logfile = '{:s}_{:s}.out'.format('archive_restart', end_date_str)
              cmd_tmpl = 'sbatch --output={log:s} --error={log:s} {job:s} {d:s}'
              cmd = cmd_tmpl.format(job=self._archive_rst_job, d=end_date_str, log=logfile)
              print("submitting restart archive with check_call('" + cmd + "', shell=True)")
              check_call(cmd, shell=True)


          def _run_fun(self):
              # Determine run command
              if self.cosmo_only:
                  if self.gpu_mode:
                      run_cmd = 'srun -u --ntasks-per-node=1 -n {:d} {:s}'.format(self._n_nodes, self.cos_exe)
                  else:
                      run_cmd = 'srun -u -n {:d} {:s}'.format(self._n_nodes * self._n_tasks_per_node, self.cos_exe)
              else:
                  run_cmd = 'srun -u --multi-prog ./proc_config'

              # Run
              check_call(['module list'], shell=True)
              print("running " + run_cmd)
              sys.stdout.flush()
              check_call(run_cmd, shell=True)


          def _build_proc_config(self):

              # Build executable bash files
              f_path = os.path.join(self.path, 'cosmo.bash')
              with open(f_path, 'w') as f:
                  f.write("#!/bin/bash\n")
                  if self.gpu_mode: 
                      f.write("export MPICH_RDMA_ENABLED_CUDA=1\n")
                  f.write("./{:s}".format(self.cos_exe))
              os.chmod(f_path, 0o755)
              f_path = os.path.join(self.path, 'cesm.bash')
              with open(f_path, 'w') as f:
                  f.write("#!/bin/bash\n")
                  if self.gpu_mode:
                      f.write("export MPICH_RDMA_ENABLED_CUDA=0\n")
                  f.write("./{:s}".format(self.cesm_exe))
              os.chmod(f_path, 0o755)

              # Build proc_config
              with open(os.path.join(self.path, 'proc_config'), mode='w') as f:
                  if self.gpu_mode:
                      N = self._n_tasks_per_node
                      tasks = ",".join([str(k*N) for k in range(self._n_nodes)])
                      f.write("{:s} ./cosmo.bash\n".format(tasks))
                      tasks = ",".join(["{:d}-{:d}".format(k*N+1,(k+1)*N-1) for k in range(self._n_nodes)])
                      f.write("{:s} ./cesm.bash".format(tasks))
                  else:
                      f.write('{:d}-{:d} ./cosmo.bash\n'.format(0, self._ncos-1))
                      f.write('{:d}-{:d} ./cesm.bash'.format(self._ncos, self._ncos+self._ncesm-1))
    #+END_SRC

*** mistral_case class
    - [ ] Also rewrite without _update_bla methods for Mistral
    #+BEGIN_SRC python
      @available
      class mistral_case(cc2_case):
          """Class defining a COSMO-CLM2 case on Mistral"""

          _target_machine='mistral'
          _n_tasks_per_node = 24


          def __init__(self, run_time='08:00:00', account=None, partition=None,
                       transfer_time='02:00:00', archive_time='03:00:00', **base_case_args):

              self.run_time = run_time
              self.account = account
              self.partition = partition
              cc2_case.__init__(self, **base_case_args)
              if self.gpu_mode:
                  raise NotImplementedError("gpu mode not implemented for " + self.__class__.__name__)


          def _build_proc_config(self):

              with open(os.path.join(self.path, 'proc_config'), mode='w') as f:
                  f.write('{:d}-{:d} ./{:s}\n'.format(0, self._ncos-1, self.COSMO_exe))
                  if not self.cosmo_only:
                      f.write('{:d}-{:d} ./{:s}\n'.format(self._ncos, self._ncos+self._ncesm-1, self.CESM_exe))


          def _build_run_job(self):

              # shebang
              script_str = '#!/usr/bin/env bash\n\n'

              # slurm options
              scripte_str +='#SBATCH --job-name={:s}\n'.format(self.name)
              scripte_str +='#SBATCH --nodes={:d}\n'.format(self._n_nodes)
              scripte_str +='#SBATCH --account={:s}\n'.format(self.account)
              scripte_str +='#SBATCH --time={:s}\n'.format(self.run_time)
              if self.partition is not None:
                  scripte_str += '#SBATCH --partition={:s}\n'.format(self.partition)

              # environment variables
              scripte_str += 'export LD_LIBRARY_PATH=/sw/rhel6-x64/netcdf/netcdf_fortran-4.4.3-parallel-openmpi2-intel14/lib/:/sw/rhel6-x64/netcdf/parallel_netcdf-1.6.1-openmpi2-intel14/lib\n\n'
              script_str += '# Set this to avoid segmentation faults\n'
              script_str += 'ulimit -s unlimited\n'
              script_str += 'ulimit -a\n\n'
              script_str += 'export OMP_NUM_THREADS=1\n\n'

              # launch case
              scripte_str += 'cc2_control_case ./{:s}\n'.format(self._xml_config)

              with open(os.path.join(self.path, self._run_job), mode='w') as script:
                  script.write(script_str)


          def _submit_run_cmd(self, d1, d2):

              d1_str = d1.strftime(date_fmt['cesm'])
              d2_str = d2.strftime(date_fmt['cesm'])
              logfile = '{:s}_{:s}-{:s}.out'.format(self.name, d1_str, d2_str)

              cmd_tmpl = 'sbatch --output={log:s} --error={log:s} {job:s}'
              cmd = cmd_tmpl.format(log=logfile, job=self._run_job)
              print("submitting run with check_call('" + cmd + "', shell=True)")
              check_call(cmd, shell=True)


          def _run_fun(self):
              if self.cosmo_only:
                  run_cmd = 'srun -u -n {:d} {:s}'.format(self._n_nodes * self._n_tasks_per_node, self.COSMO_exe)
              else:
                  self._build_proc_config()
                  run_cmd = 'srun -u --multi-prog ./proc_config'
              print("running " + run_cmd)
              sys.stdout.flush()
              check_call(run_cmd, shell=True)
    #+END_SRC
*** nmldict class
    #+BEGIN_SRC python
      class nmldict(dict):
          """Dictionnary of all the namelists of a case. Only load the namelist if needed"""
          def __init__(self, cc2case):
              dict.__init__(self)
              self.cc2case = cc2case

          def __getitem__(self, key):
              if key not in self:
                  self[key] = f90nml.read(os.path.join(self.cc2case.path, key))
              return dict.__getitem__(self, key)

          def write(self, name):
              self[name].write(os.path.join(self.cc2case.path, name), force=True)

          def write_all(self):
              for name in self:
                  self.write(name)
    #+END_SRC

** create_case.py
   :PROPERTIES:
   :header-args: :tangle COSMO_CLM2_tools/create_case.py :comments no
   :END:
*** preamble
    #+BEGIN_SRC python
      from __future__ import print_function
      from .cc2_case import factory as cc2_case_factory, available_cases
      from .tools import date_fmt, get_xml_node_args
      from subprocess import check_call
      from argparse import ArgumentParser, RawTextHelpFormatter, Action as arg_action
      import f90nml
      from datetime import datetime, timedelta
      import os
      import xml.etree.ElementTree as ET
      import shutil
    #+END_SRC
*** create_case
    - [ ] For now, no choice for the I/O directory structure. Maybe no
      need to implement this.
    #+BEGIN_SRC python
      def create_case():
          """
          Create a Cosmo-CLM2 case from cmd line arguments and xml setup file

          See ``cc2_create_case --help``
          """

          # Build command line parser
          # =========================

          # Custom action factory to fill in cc2_cmd_args dictionnary
          cc2_cmd_args = {}
          case_actions = {}

          def cc2_act(*groups):

              for group in groups:
                  if group not in cc2_cmd_args:
                      cc2_cmd_args[group] = {}

              key = '.'.join(groups)

              if key not in case_actions:
                  def call(self, parser, args, values, option_string=None):
                      for group in self.cc2_groups:
                          cc2_cmd_args[group][self.dest] = values
                  name = 'cc2_' + '_'.join(groups)
                  case_actions[key] = type(name, (arg_action,),{'__call__': call, 'cc2_groups': groups})

              return case_actions[key]

          # function for boolean type
          def str_to_bool(val_str):
              return bool(eval(val_str))

          # Create parser
          dsc = "Set up and run a COSMO_CLM2 case\n"\
                "--------------------------------\n"\
                "Options can be set up either by xml file or the following command line arguments.\n"\
                "xml file options must be stored in a subelement of the root element tagged with 'main'.\n"\
                "and/or the specific machine (see [1]).\n"\
                "Command line arguments have precedence over xml file ones.\n"\
                "[1] https://github.com/COSMO-RESM/COSMO_CLM2_tools/blob/master/COSMO_CLM2_tools/example_setup.xml"
          parser = ArgumentParser(description=dsc, formatter_class=RawTextHelpFormatter)
          parser.add_argument('-s', '--setup-file', metavar='FILE', help="xml file conatining setup options")
          parser.add_argument('--machine', metavar='MACH',
                              help="machine on which the case is running (default: has to be given \n"
                              "either by the command line or the xml setup file)")
          main_group = parser.add_argument_group('main', 'Case options common to all machines')
          main_group.add_argument('--name', action=cc2_act('main'), help="case name (default: COSMO_CLM2)")
          main_group.add_argument('--install_dir', action=cc2_act('main'),
                                  help="directory where the case is installed (default: $SCRATCH on daint)")
          main_group.add_argument('--archive_dir', action=cc2_act('main'),
                                  help="directory where output and restart files are archived (default: None)")
          main_group.add_argument('--archive_rm', action=cc2_act('main'), type=str_to_bool,
                                  help="remove original output files from the case directory when archiving\n"
                                  "(type: bool, using anything Python can parse as a boolean, default: False)")
          main_group.add_argument('--archive_per_month', action=cc2_act('daint'), type=str_to_bool,
                                   help="submit one archiving job per month. For massive output simulations.\n"
                                   "(type: bool, using anything Python can parse as a boolean, default: False)")
          main_group.add_argument('--archive_compression', action=cc2_act('daint'), choices=['none', 'gzip', 'bzip2'],
                                   help="select the compression algorithm (default: 'gzip')")
          main_group.add_argument('--archive_cesm', action=cc2_act('daint'), type=str_to_bool,
                                   help="archive cesm output or not\n"
                                   "(type: bool, using anything Python can parse as a boolean, default: True)")
          main_group.add_argument('--start_date', metavar='DATE_1', action=cc2_act('main'),
                                  help="simulation start date formatted as YYYY-MM-DD-HH")
          main_group.add_argument('--end_date', metavar='DATE_2', action=cc2_act('main'),
                                  help="simulation end date formatted as YYYY-MM-DD-HH")
          main_group.add_argument('--run_length', metavar='dt', action=cc2_act('main'),
                                  help="sets simulation length if end_date not specified or run length\n"
                                  "between restarts otherwise\n"
                                  "dt is of the form 'N1yN2m', 'N1y', 'N2m' or 'N3d'\n"
                                  "N1, N2 and N4 being arbitrary integers (N2>12 possible) and\n"
                                  "'y', 'm' and 'd' standing for years, months and days")
          main_group.add_argument('--cos_in', action=cc2_act('main'),
                                  help="COSMO input files directory (default: ./COSMO_input)")
          main_group.add_argument('--cos_nml', action=cc2_act('main'),
                                  help="COSMO namelists directory (default: ./COSMO_nml)")
          main_group.add_argument('--cos_exe', action=cc2_act('main'),
                                  help="path to COSMO executable (default: ./cosmo)")
          main_group.add_argument('--cesm_in', action=cc2_act('main'),
                                  help="CESM input files directory (default: ./CESM_input)")
          main_group.add_argument('--cesm_nml', action=cc2_act('main'),
                                  help="CESM namelists directory (default: ./CESM_nml)")
          main_group.add_argument('--cesm_exe', action=cc2_act('main'),
                                  help="CESM executable (default: ./cesm.exe)")
          main_group.add_argument('--oas_in', action=cc2_act('main'),
                                  help="OASIS input files directory (default: ./OASIS_input)")
          main_group.add_argument('--oas_nml', action=cc2_act('main'),
                                  help="OASIS namelists directory (default: ./OASIS_nml)")
          main_group.add_argument('--ncosx', action=cc2_act('main'), type=int,
                                  help="number of subdomains along the 'x-axis'\n"
                                  "for COSMO domain decomposition (type: int, default: from INPUT_ORG namelist)")
          main_group.add_argument('--ncosy', action=cc2_act('main'), type=int,
                                  help="number of subdomains along the 'y-axis'\n"
                                  "for COSMO domain decomposition (type: int, default: from INPUT_ORG namelist)")
          main_group.add_argument('--ncosio', action=cc2_act('main'), type=int,
                                  help="number of cores dedicated to i/o work\n"
                                  "(type: int, default: from INPUT_ORG namelist)")
          main_group.add_argument('--ncesm', action=cc2_act('main'), type=int,
                                  help="number of subdomains for CESM domain decomposition'\n"
                                  "(type: int, default: from drv_in namelist)")
          main_group.add_argument('--cosmo_only', action=cc2_act('main'), type=str_to_bool,
                                  help="run only cosmo with build-in soil model TERRA\n"
                                  "(type: bool, using anything Python can parse as a boolean, default: False)\n"
                                  "Be carefull to provide a COSMO executable compiled accordingly")
          main_group.add_argument('--start_mode', action=cc2_act('main'), type=str_to_bool,
                                  choices=['startup', 'continue', 'restart'],
                                  help="if not startup, use in conjunction with restart_date,\n"
                                  "cos_rst and CESM_rst options (default: 'startup')")
          main_group.add_argument('--restart_date', action=cc2_act('main'),
                                  help="restart date formatted as YYYY-MM-DD-HH (default: None)")
          main_group.add_argument('--cos_rst', action=cc2_act('main'),
                                  help="path to the COSMO restart file. Compresed restart files\n"
                                  "with extension '.gz' or '.bz2' are accepted. (default: None)")
          main_group.add_argument('--cesm_rst', action=cc2_act('main'),
                                  help="path to the directory containing CESM restart files.\n"
                                  "Archives, compresed or not, with extension '.tar', '.tgz', '.tar.gz',\n"
                                  " '.tbz' or '.tar.bz2' are accepted. (default: None)")
          main_group.add_argument('--gpu_mode', action=cc2_act('main'), type=str_to_bool,
                                  help="run COSMO on gpu (type: bool, using anything Python can parse as a boolean,\n"
                                  "default: False)")
          main_group.add_argument('--dummy_day', action=cc2_act('main'), type=str_to_bool,
                                  help="perform a dummy day run after end of simulation to get last COSMO output.\n"
                                  "(type: bool, using anything Python can parse as a boolean, default: True)")
          main_group.add_argument('--input_type', action=cc2_act('main'), choices=['file', 'symlink'],
                                  help="default: file")
          main_group.add_argument('--transfer_all', action=cc2_act('main'), type=str_to_bool,
                                  help="Transfer all model input files at once before starting the simulation\n"
                                  "(type: bool, using anything Python can parse as a boolean, default: True)")

          slurm_group = parser.add_argument_group('slurm', 'Options specific to the slurm workload manager.\n'\
                                                  '(common to all machines using the slurm scheduler)')
          slurm_group.add_argument('--run_time', action=cc2_act('daint', 'mistral'),
                                  help="reserved time for run job\n"
                                  "(default: '24:00:00' on daint, '08:00:00' on mistral)")
          slurm_group.add_argument('--transfer_time', action=cc2_act('daint', 'mistral'),
                                  help="reserved time for transfer job (default: '02:00:00')")
          slurm_group.add_argument('--archive_time', action=cc2_act('daint', 'mistral'),
                                  help="reserved time for archive job (default: '03:00:00')")
          slurm_group.add_argument('--account', action=cc2_act('daint', 'mistral'),
                                   help="account to use for batch script\n"
                                   "(default: infered from $PROJECT on daint, None on mistral)")
          slurm_group.add_argument('--partition', action=cc2_act('daint', 'mistral'),
                                   help="select a queue (default: None)")

          daint_group = parser.add_argument_group('daint', 'Options specific to the Piz Daint machine')
          daint_group.add_argument('--modules_opt', action=cc2_act('daint'), choices=['switch', 'none', 'purge'],
                                   help="option for loading modules at run time (default: switch)")
          daint_group.add_argument('--pgi_version', action=cc2_act('daint'),
                                   help="specify pgi compiler version at run time (default: None)")
          daint_group.add_argument('--shebang', action=cc2_act('daint'),
                                   help="submit script shebang (default: #!/bin/bash)")

          cmd_line_group = parser.add_argument_group('cmd line', 'Options only avialble to the command line (no xml)')
          cmd_line_group.add_argument('--no_submit', action='store_false', dest='submit',
                                      help="do not submit job after setup\n"
                                      "only command line argument, cannot be set in xml file")
          cmd_line_group.add_argument('--gen_oasis', action='store_true',
                                      help="generate OASIS auxiliary files\n"
                                      "note that OASIS will crash after producing the files\n"
                                      "only command line argument, cannot be set in xml file\n")

          opts = parser.parse_args()

          # Parse machine and case argumennts from cmd line args and xml file
          # =================================================================
          machine, cc2_args = get_case_args(opts, cc2_cmd_args)

          # Create case instance
          # ====================
          cc2case = cc2_case_factory(machine, install=True, **cc2_args)

          # Change/delete namelists parameters following xml file
          # =====================================================
          modify_nml_from_xml(cc2case, opts)

          # Submit case
          # ===========
          if opts.submit:
              cc2case.run_status = 'submitted'
              cc2case.submit_run()
    #+END_SRC
*** get_case_args
    #+BEGIN_SRC python
      def get_case_args(cmd_opts, cc2_cmd_args):

          if cmd_opts.gen_oasis:
              cc2_cmd_args['main']['dummy_day'] = False

          machine = cmd_opts.machine

          xml_file = cmd_opts.setup_file
          if xml_file is not None:
              tree_root = ET.parse(xml_file).getroot()
              main_node = tree_root.find('main')
              if machine is None:
                  machine_name_node = tree_root.find('machine')
                  if machine_name_node is not None:
                      machine = machine_name_node.text
              machine_node = tree_root.find(machine)

          if machine is None:
              raise ValueError("'machine' option has to be given either by the command line or the xml setup file")

          main_args = get_xml_node_args(main_node) if xml_file is not None else {}
          main_args.update(cc2_cmd_args['main'])

          machine_args = get_xml_node_args(machine_node) if xml_file is not None else {}
          machine_args.update(cc2_cmd_args[machine])

          cc2_args = {k:v for k,v in main_args.items() if v is not None}
          cc2_args.update({k:v for k,v in machine_args.items() if v is not None})

          return machine, cc2_args
    #+END_SRC
*** modify_nml_from_xml
    #+BEGIN_SRC python
      def modify_nml_from_xml(cc2case, cmd_opts):
          """Modify case namelists following instructions from xml setup file"""

          if cmd_opts.setup_file is None:
              return

          tree_root = ET.parse(cmd_opts.setup_file).getroot()

          # Change parameters
          nodes = tree_root.findall('change_par')
          if nodes:
              for node in nodes:
                  name = node.get('file')
                  block = node.get('block')
                  n = node.get('n')
                  param = node.get('param')
                  val_str = node.text
                  if name is None:
                      raise ValueError("'file' xml attribute is required to change parameter")
                  if block is None:
                      raise ValueError("'block' xml attribute is required to change parameter")
                  if param is None:
                      raise ValueError("'param' xml attribute is required to change parameter")
                  if node.get('type') is None:
                      value = val_str
                  elif node.get('type') == 'py_eval':
                      value = eval(val_str)
                  else:
                      val_type = eval(node.get('type'))
                      if isinstance(val_type, type):
                          value = val_type(val_str)
                      else:
                          err_mess = "Given xml atribute 'type' for parameter {:s} is {:s}\n"\
                                     "It has to be either 'py_eval' or a valid build in python type"
                          raise ValueError(err_mess.format(param, val_type))
                  if n is None:
                      cc2case.nml[name][block][param] = value
                  else:
                      cc2case.nml[name][block][int(n)-1][param] = value

          # Delete parameters
          nodes = tree_root.findall('del_par')
          if nodes:
              for node in nodes:
                  name = node.get('file')
                  block = node.get('block')
                  n = node.get('n')
                  param = node.get('param')
                  if name is None:
                      raise ValueError("'file' xml attribute is required to delete parameter")
                  if block is None:
                      raise ValueError("'block' xml attribute is required to delete parameter")
                  if param is None:
                      raise ValueError("'param' xml attribute is required to delete parameter")
                  if n is None:
                      del cc2case.nml[name][block][param]
                  else:
                      del cc2case.nml[name][block][int(n)-1][param]

          # Write namelists to file
          cc2case.write_open_nml()
    #+END_SRC
** control_case.py
   - [ ] The xml part of it could go to a bla_from_xml factory function
   #+BEGIN_SRC python :tangle COSMO_CLM2_tools/control_case.py :comments no
     from .cc2_case import factory as cc2_case_factory
     from .tools import get_xml_node_args
     from argparse import ArgumentParser, RawTextHelpFormatter
     import xml.etree.ElementTree as ET
     from time import sleep


     def control_case():
         # Parse arguments
         dsc = "Control a COSMO_CLM2 case"
         parser = ArgumentParser(description=dsc, formatter_class=RawTextHelpFormatter)
         parser.add_argument('xml_path', help="path to xml file containing case description")
         parser.add_argument('--action', choices=['run', 'transfer'], default='run',
                             help="path to xml file containing case description")
         cfg = parser.parse_args()

         # build cc2case object from xml file
         config = ET.parse(cfg.xml_path).getroot()
         machine = config.find('machine').text
         case_args = get_xml_node_args(config.find('main'))
         case_args.update(get_xml_node_args(config.find(machine)))
         cc2case = cc2_case_factory(machine, **case_args)

         if cfg.action == 'run':
        
             # set run status
             cc2case.run_status = 'running'

             # Submit next transfer
             if (cc2case._run_end_date < cc2case.end_date and cc2case.transfer_by_chunck):
                 cc2case.transfer_status = 'submitted'
                 cc2case.submit_next_transfer()

             # Run
             cc2case.run()
             cc2case.set_next_run()

             # Archive
             if cc2case.archive_dir is not None:
                 cc2case.submit_archive()

             # Submit next run and set run status
             if (cc2case._run_end_date < cc2case.end_date and cc2case.transfer_status == 'complete'):
                 cc2case.run_status = 'submitted'
                 cc2case.submit_next_run()
             else:
                 cc2case.run_status = 'complete'

         elif cfg.action == 'transfer':
        
             # set transfer status
             cc2case.transfer_status = 'transferring'

             # Transfer
             cc2case.transfer_input()

             # Submit next run
             if cc2case.run_status == 'complete':
                 cc2case.run_status = 'submitted'
                 cc2case.submit_next_run()

             # set transfer status
             cc2case.transfer_status = 'complete'
   #+END_SRC
** tools.py
   - [ ] Problem with empty nodes
   #+BEGIN_SRC python :tangle COSMO_CLM2_tools/tools.py :comments no
     from datetime import datetime, timedelta
     date_fmt = {'in': '%Y-%m-%d-%H', 'cosmo': '%Y%m%d%H','cesm': '%Y%m%d'}

     def COSMO_input_file_name(root, date, ext):
         return root + date.strftime(date_fmt['cosmo']) + ext


     def add_time_from_str(date1, dt_str):
         """Increment date from a string

         Return the date resulting from date + N1 years + N2 months or date + N3 days
         where dt_str is a string of the form 'N1yN2m' or 'N1y' or 'N2m' or 'N3d',
         N1, N2 and N3 being arbitrary integers potentially including sign and
         'y', 'm' and 'd' the actual letters standing for year, month and day respectivly."""

         ny, nm, nd, nh = None, None, None, None
         ks = 0
         for ke, c in enumerate(dt_str):
             if c == 'y':
                 ny = int(dt_str[ks:ke])
                 ks = ke+1
             elif c == 'm':
                 nm = int(dt_str[ks:ke])
                 ks = ke+1
             elif c == 'd':
                 nd = int(dt_str[ks:ke])
                 ks = ke+1
             elif c == 'h':
                 nh = int(dt_str[ks:ke])
                 ks = ke+1

         # Compute new date
         if ny is not None or nm is not None:
             y2, m2, d2, h2 = date1.year, date1.month, date1.day, date1.hour
             if ny is not None:
                 y2 += ny
             if nm is not None:
                 y2 += (nm+m2-1) // 12
                 m2 = (nm+m2-1) % 12 + 1
             return datetime(y2, m2, d2, h2)
         elif nd is not None:
             return date1 + timedelta(days=nd)
         elif nh is not None:
             return date1 + timedelta(hours=nh)
         else:
             raise ValueError("date increment '" + dt_str + "' doesn't have the correct format")


     def get_xml_node_args(node, exclude=()):
         """Read case arguments from xml node"""

         if node is None:
             return {}

         xml_args = {}

         for opt in node.iter():
             if opt is not node and opt.tag not in exclude:
                 if opt.text is None:
                     xml_args[opt.tag] = None
                 elif opt.get('type') is None:
                     xml_args[opt.tag] = opt.text
                 elif opt.get('type') == 'py_eval':
                     xml_args[opt.tag] = eval(opt.text)
                 else:
                     opt_type = eval(opt.get('type'))
                     if isinstance(opt_type, type):
                         xml_args[opt.tag] = opt_type(opt.text)
                     else:
                         raise ValueError("xml atribute 'type' " + opt.get('type')
                                          + " for node " + opt.tag
                                          + " has to be a valid python type or 'py_eval'")

         return xml_args


     def indent_xml(elem, level=0):
         i = "\n" + level*"  "
         if len(elem):
             if not elem.text or not elem.text.strip():
                 elem.text = i + "  "
             if not elem.tail or not elem.tail.strip():
                 elem.tail = i
             for elem in elem:
                 indent_xml(elem, level+1)
             if not elem.tail or not elem.tail.strip():
                 elem.tail = i
         else:
             if level and (not elem.tail or not elem.tail.strip()):
                 elem.tail = i
   #+END_SRC
** compile_clm.py
   #+BEGIN_SRC python :tangle COSMO_CLM2_tools/compile_clm.py :comments no
     from argparse import ArgumentParser, RawTextHelpFormatter
     from glob import glob
     from subprocess import check_call
     import os
     from shutil import rmtree


     def compile_clm():

         # Define and parse command line arguments
         # ---------------------------------------

         dsc = "Compile CLM on Piz Daint. A case will be created in a subfolder of your ${SCRATCH}.\n"\
               " WARNING: tool has to be run from the default Prg-Env-cray environment"
         parser = ArgumentParser(description=dsc, formatter_class=RawTextHelpFormatter)
         parser.add_argument('cesm_trunk', help="path to the CESM directory")
         parser.add_argument('--clm_version', choices=['4.0, 4.5'], default='4.0', help="CLM version")
         parser.add_argument('-c', '--compiler', help="compiler to use (default: pgi)", default='pgi')
         parser.add_argument('-v', '--compiler_version', help="switch to this version of the compiler\n"\
                             "This is not recommended by CSCS")
         parser.add_argument('-d', '--debug', help="compile in debug mode (default: false)",
                             action='store_true')
         parser.add_argument('--src_mod', action='append',
                             help="path to additionnal/modified sources (e.g. oasis interface)\n"\
                             "has to be a folder containing src.xxx subfolders, can be specified several times")
         parser.add_argument('-o', '--output', help="output executable file path (default: ./cesm.exe)",
                             default='./cesm.exe')
         parser.add_argument('--no_exe', help="do not execute build_cesm.bash, leave it to any suited modification before actual compilation.",
                             action='store_false', dest='execute')
         opts = parser.parse_args()


         # Init some variables
         # -------------------

         CESM_TRUNK = opts.cesm_trunk
         EXP = 'clm{:s}_bld'.format(opts.clm_version)
         CASEDIR = os.path.join(os.environ['SCRATCH'], EXP)
         if os.path.exists(CASEDIR):
             rmtree(CASEDIR)
         RES = '1.9x2.5_gx1v6'
         COMP = 'ITEST'
         MACH = 'daint'
         if opts.clm_version == '4.5':
             COMP += 'CLM45'

         out_exe = os.path.abspath(opts.output)
         sourcemods = [os.path.abspath(src_dir) for src_dir in opts.src_mod]

         create_case_fmt = '{:s}/scripts/create_newcase -res {:s} -compset {:s} -mach {:s} -compiler pgi_oas -case {:s}'
         create_case_cmd = create_case_fmt.format(CESM_TRUNK, RES, COMP, MACH, CASEDIR)

         # Build compiling script
         # ----------------------

         with open('build_cesm.bash', mode='w') as script:
             script.write('#!/bin/bash\n')
             script.write('\n')
             script.write('# ----------------------------------------------\n')
             script.write('# Modules\n')
             script.write('# ----------------------------------------------\n')
             script.write('\n')
             if opts.compiler == 'pgi':
                 script.write('module switch PrgEnv-cray PrgEnv-pgi\n')
                 if opts.compiler_version is not None:
                     script.write('module switch pgi pgi/{:s}\n'.format(opts.compiler_version))
             elif opts.compiler == 'intel':
                 script.write('module switch PrgEnv-cray PrgEnv-intel\n')
                 if opts.compiler_version is not None:
                     script.write('module switch intel intel/{:s}\n'.format(opts.compiler_version))
             elif opts.compiler == 'cray' and opts.compiler_version is not None:
                 script.write('module switch cce cce/{:s}\n'.format(opts.compiler_version))
             script.write('\n')
             script.write('module load cray-netcdf\n')
             script.write('module load daint-gpu\n')
             script.write('\n')
             script.write('module list\n')
             script.write('\n')
             script.write('# ----------------------------------------------\n')
             script.write('# Create case\n')
             script.write('# ----------------------------------------------\n')
             script.write('\n')
             script.write('{:s}\n'.format(create_case_cmd))
             script.write('\n')
             script.write('# ----------------------------------------------\n')
             script.write('# Setup case\n')
             script.write('# ----------------------------------------------\n')
             script.write('\n')
             script.write('cd {:s}\n'.format(CASEDIR))
             script.write('\n')
             script.write('switch off river routing\n')
             script.write('./xmlchange RTM_MODE="NULL"\n')
             script.write('\n')
             script.write('set transient CO2\n')
             script.write('./xmlchange CCSM_BGC=CO2A,CLM_CO2_TYPE=diagnostic\n')
             if opts.debug:
                 script.write('# activate debug mode\n')
                 script.write('./xmlchange -file env_build.xml -id DEBUG -val "TRUE"\n')
             script.write('\n')
             script.write('./cesm_setup\n')
             script.write('\n')
             script.write('# ----------------------------------------------\n')
             script.write('# Add source additions/modifications\n')
             script.write('# ----------------------------------------------\n')
             script.write('\n')
             for src_dir in sourcemods:
                 print(src_dir)
                 for comp in glob('{:s}/src.*'.format(src_dir)):
                     print(comp)
                     script.write('rsync -avrL {:s} SourceMods\n'.format(comp))
             script.write('\n')
             script.write('# ----------------------------------------------\n')
             script.write('# Build\n')
             script.write('# ----------------------------------------------\n')
             script.write('\n')
             script.write('{:s}.build\n'.format(EXP))
             script.write('rsync -avr bld/cesm.exe {:s}\n'.format(out_exe))

         os.chmod('build_cesm.bash', 0o755)


         # Execute compiling script
         # ------------------------

         if opts.execute:
             check_call(['./build_cesm.bash'])

   #+END_SRC
   
** __init__.py
   #+BEGIN_SRC python :tangle COSMO_CLM2_tools/__init__.py :comments no
     __version__ = '0.3'
   #+END_SRC

* setup.py                                                         :noexport:
  #+BEGIN_SRC python :tangle setup.py :comments no
    import os
    from setuptools import setup

    def get_version():
        with open('COSMO_CLM2_tools/__init__.py') as f:
            for line in f:
                if line.startswith('__version__'):
                    _, _, version = line.replace("'", '').split()
                    break
        return version

    setup(name='COSMO_CLM2_tools',
          version=get_version(),
          description="python based tools to set up a COSMO_CLM2 case",
          author="Matthieu Leclair",
          author_email="matthieu.leclair@env.ethz.ch",
          url="https://github.com/COSMO-RESM/COSMO-CLM2_tools",
          packages=['COSMO_CLM2_tools'],
          entry_points={'console_scripts': ['cc2_create_case = COSMO_CLM2_tools.create_case:create_case',
                                            'cc2_control_case = COSMO_CLM2_tools.control_case:control_case',
                                            'cc2_compile_clm = COSMO_CLM2_tools.compile_clm:compile_clm']},
          install_requires=['f90nml>=1.0.2']
    )
  #+END_SRC

* Notes                                                            :noexport:
** DONE Enable COSMO only                                               :dev:
